{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing sklearn packages, creating custom tokenizer, text preprocessor and salary prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note there are limited features - Only region(referred to as location in the exercise),job_category,country are used as initial features\n",
    "\n",
    "#Using summary variable with textual analysis to create additional features based on the Tfidf values\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV\n",
    "\n",
    "#Conducting analysis with one feature 'region'; dropping all other columns\n",
    "columns_to_drop = ['job_title','company','location','salary','link','summary','exch_rate','pay_rate','lower','upper','median_salary']\n",
    "\n",
    "tfidfmax_features = 10\n",
    "\n",
    "#Creating a function to do custom tokenizers of string which are segmented and split\n",
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    return words\n",
    "\n",
    "#creating list of stopwords from english\n",
    "stopwordz = stopwords.words('english')\n",
    "\n",
    "\n",
    "#Creating text preprocessing for only job summary \n",
    "text_preprocessor = ('text', Pipeline([('colext', TextSelector('summary')),('tfidf', TfidfVectorizer(tokenizer=Tokenizer, stop_words=list(set(stopwordz)),\n",
    "                     min_df=.0025, max_df=0.9, max_features=tfidfmax_features,ngram_range=(1,3))), ]))\n",
    "\n",
    "#Creating salary preprocessing for existing categorical variables\n",
    "salary_preprocessor = ('nominal',Pipeline([('salary_prep', SalaryPreprocessor(columns_to_drop=columns_to_drop)),\n",
    "                                           ('encoder',OneHotEncoder(categories = \"auto\",sparse=False,handle_unknown='ignore')),]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing function to conduct model comparison with pipelines\n",
    "def model_compare(classifier1,classifier2,params1,params2):\n",
    "    \n",
    "    #Creating loop for gridsearch of both classifiers with one feature\n",
    "    for clf,param in zip([classifier1,classifier2],[params1,params2]):\n",
    "        grid_cv = GridSearchCV(clf,param_grid=param,cv=5,verbose=2,n_jobs=-1)\n",
    "        grid_cv.fit(X_train,y_train)\n",
    "        estimator_name = re.search(r\"\\.([A-Z]+.[A-Za-z]+)\",str(grid_cv.get_params()['estimator__clf'].__class__)).group(1)\n",
    "        print(end='\\n')\n",
    "        print(f\"{estimator_name} cross-validated score:  {grid_cv.best_score_:.3f}\",end='\\n')\n",
    "        print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conducting analysis with one feature 'region'; dropping all other columns\n",
    "#columns_to_drop = ['job_title', 'company', 'location', 'salary',\n",
    "       #'link', 'summary', 'country', 'exch_rate', 'pay_rate', 'lower', 'upper',\n",
    "       #'median_salary']\n",
    "\n",
    "#tfidfmax_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conducting analysis with one feature\n",
    "\n",
    "#Defining classifier1 - Logistic Regression with one feature 'region'\n",
    "classifier1 = Pipeline([\n",
    "    ('features', FeatureUnion([text_preprocessor,salary_preprocessor])),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression())])\n",
    "\n",
    "#Defining parameters for classifier1 for gridsearch\n",
    "params1 = {'clf__C': np.logspace(-4,4),\n",
    " 'clf__class_weight': [None],\n",
    " 'clf__fit_intercept': [True,False],\n",
    " 'clf__multi_class': ['auto'],\n",
    " 'clf__penalty': ['l2','l1'],\n",
    " 'clf__random_state': [0],\n",
    " 'clf__solver': ['liblinear'],\n",
    " 'clf__verbose': [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining classifier2 - DecisionTree with one feature 'region'\n",
    "classifier2 = Pipeline([\n",
    "    ('features', FeatureUnion([text_preprocessor,salary_preprocessor])),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "#Defining parameters for classifier2 for gridsearch\n",
    "params2= {'clf__class_weight': [None],\n",
    " 'clf__criterion': ['gini','entropy'],\n",
    " 'clf__max_depth': list(range(2,20)),\n",
    " 'clf__max_features': list(range(2,6))+[None],\n",
    " 'clf__max_leaf_nodes': list(range(2,6))+[None],\n",
    " 'clf__random_state': [0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating loop for gridsearch of both classifiers with one feature\n",
    "for clf,param in zip([classifier1,classifier2],[params1,params2]):\n",
    "    grid_cv = GridSearchCV(clf,param_grid=param,cv=5,verbose=2,n_jobs=-1)\n",
    "    grid_cv.fit(X_train,y_train)\n",
    "    estimator_name = re.search(r\"\\.([A-Z]+.[A-Za-z]+)\",str(grid_cv.get_params()['estimator__clf'].__class__)).group(1)\n",
    "    print(end='\\n')\n",
    "    print(f\"{estimator_name} cross-validated score:  {grid_cv.best_score_:.3f}\",end='\\n')\n",
    "    print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining classifier1 - Logistic Regression with textual features only\n",
    "classifier1 = Pipeline([\n",
    "    ('features', FeatureUnion([text_preprocessor])),\n",
    "    ('clf', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "#Defining parameters for gridsearch\n",
    "params1 = {'clf__C': np.logspace(-1,0,10),\n",
    " 'clf__class_weight': [None],\n",
    " 'clf__fit_intercept': [True],\n",
    " 'clf__multi_class': ['auto'],\n",
    " 'clf__penalty': ['l2','l1'],\n",
    " 'clf__random_state': [0],\n",
    " 'clf__solver': ['liblinear'],\n",
    " 'clf__verbose': [2]}\n",
    "\n",
    "\n",
    "#Defining classifier2 - DecisionTree with textual features only\n",
    "classifier2 = Pipeline([\n",
    "    ('features', FeatureUnion([text_preprocessor])),\n",
    "    ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "params2= {'clf__class_weight': [None],\n",
    " 'clf__criterion': ['gini'],\n",
    " 'clf__max_depth': list(range(2,4)),\n",
    " 'clf__max_features': [None],\n",
    " 'clf__max_leaf_nodes': list(range(5,6))+[None],\n",
    " 'clf__random_state': [0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Including region, job level, \n",
    "columns_to_drop = ['job_title', 'company', 'location', 'salary',\n",
    "       'link', 'summary', 'country', 'exch_rate', 'pay_rate', 'lower', 'upper',\n",
    "       'median_salary','job_category','level']\n",
    "\n",
    "tfidfmax_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf,param in zip([classifier1,classifier2],[params1,params2]):\n",
    "    grid_cv = GridSearchCV(clf,param_grid=param,cv=5,verbose=2,n_jobs=-1)\n",
    "    grid_cv.fit(X_train,y_train)\n",
    "    estimator_name = re.search(r\"\\.([A-Z]+.[A-Za-z]+)\",str(grid_cv.get_params()['estimator__clf'].__class__)).group(1)\n",
    "    print(end='\\n')\n",
    "    print(f\"{estimator_name} cross-validated score:  {grid_cv.best_score_:.3f}\",end='\\n')\n",
    "    print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining classifier1 - Logistic Regression with textual features only\n",
    "classifier1 = Pipeline([\n",
    "    ('features', FeatureUnion([text_preprocessor,salary_preprocessor])),\n",
    "    ('clf', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "#Defining parameters for gridsearch\n",
    "params1 = {'clf__C': np.logspace(-2,1),\n",
    " 'clf__class_weight': [None],\n",
    " 'clf__fit_intercept': [True],\n",
    " 'clf__multi_class': ['auto'],\n",
    " 'clf__penalty': ['l2','l1'],\n",
    " 'clf__random_state': [0],\n",
    " 'clf__solver': ['liblinear'],\n",
    " 'clf__verbose': [2]}\n",
    "\n",
    "\n",
    "#Defining classifier2 - DecisionTree with textual features only\n",
    "classifier2 = Pipeline([\n",
    "    ('features', FeatureUnion([text_preprocessor,salary_preprocessor])),\n",
    "    ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "params2= {'clf__class_weight': [None],\n",
    " 'clf__criterion': ['gini'],\n",
    " 'clf__max_depth': list(range(2,20)),\n",
    " 'clf__max_features': [None],\n",
    " 'clf__max_leaf_nodes': list(range(5,10))+[None],\n",
    " 'clf__random_state': [0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['job_title', 'company', 'location', 'salary',\n",
    "       'link', 'summary', 'exch_rate', 'pay_rate', 'lower', 'upper',\n",
    "       'median_salary']\n",
    "\n",
    "tfidfmax_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare(classifier1,classifier2,params1,params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(C=100)\n",
    "\n",
    "lgr.fit(TfidfVectorizer(tokenizer=Tokenizer, stop_words=list(set(stopwordz)),\n",
    "                     min_df=.0025, max_df=0.9, max_features=2,ngram_range=(1,3)).fit_transform(TextSelector('summary').fit_transform(X_train)).toarray(),y_train)\n",
    "\n",
    "lgr.score(TfidfVectorizer(tokenizer=Tokenizer, stop_words=list(set(stopwordz)),\n",
    "                     min_df=.0025, max_df=0.9, max_features=2,ngram_range=(1,3)).fit_transform(TextSelector('summary').fit_transform(X_train)).toarray(),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextSelector('summary').fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('colext', TextSelector('summary')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, stop_words=list(set(stopwordz)),\n",
    "                     min_df=.0025, max_df=0.9, max_features=tfidfmax_features,ngram_range=(1,3))),\n",
    "        ])),('nominal',Pipeline([\n",
    "            ('salary_prep', SalaryPreprocessor(columns_to_drop=columns_to_drop)),\n",
    "            ('encoder',OneHotEncoder(categories = \"auto\",sparse=False,handle_unknown='ignore')),]))\n",
    "    ])),\n",
    "    ('clf', LogisticRegression(solver='lbfgs'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(classifier,X_train,y_train,cv=5,n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred_test,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_featurenames = classifier.steps[0][1].get_params()['transformer_list'][0][1].steps[1][1].get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_featurenames = classifier.steps[0][1].get_params()['transformer_list'][1][1].steps[1][1].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames = np.concatenate((tfidf_featurenames,encoder_featurenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = classifier.steps[1][1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_table = pd.DataFrame(coefficients,columns=featurenames,index=['coef']).T\n",
    "\n",
    "coef_table['coef_abs'] = coef_table['coef'].apply(abs)\n",
    "\n",
    "coef_table.sort_values(by='coef_abs',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline,make_union\n",
    "\n",
    "columns_to_drop = ['job_title','location','salary','link','exch_rate','pay_rate','lower','upper','median_salary',\n",
    "                   'company','summary']\n",
    "\n",
    "columns_to_str=['summary']\n",
    "\n",
    "salary_prep = SalaryPreprocessor(columns_to_drop=columns_to_drop,\n",
    "                            columns_to_str=columns_to_str)\n",
    "\n",
    "encoder = OneHotEncoder(categories = \"auto\",sparse=False,handle_unknown='ignore')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps = [('sal_prep',salary_prep),('dummy',encoder),('scaler',scaler),('model',model)])\n",
    "\n",
    "FeatureUnion = make_union()\n",
    "\n",
    "fullpipe = Pipeline([('features',FeatureUnion([\n",
    "    \n",
    "    #Part 1\n",
    "    ()]))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('colext', TextSelector('Text')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, stop_words=stop_words,\n",
    "                     min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\n",
    "        ])),\n",
    "        ('words', Pipeline([\n",
    "            ('wordext', NumberSelector('TotalWords')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "    ])),\n",
    "    ('clf', XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)),\n",
    "#    ('clf', RandomForestClassifier()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(pipe,X_train,y_train,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test,y_pred_test,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack(pipe.get_params()['dummy'].categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pipe.get_params()['model'].coef_[0],index=np.hstack(pipe.get_params()['dummy'].categories_),columns=[\"coef\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer, LabelBinarizer,OrdinalEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "df1 = df[['region','level','country','job_category','salary_cat']]\n",
    "df1 = pd.get_dummies(df1,columns=['region','level','country','job_category'],drop_first=True)\n",
    "\n",
    "ordinal = OrdinalEncoder()\n",
    "\n",
    "y = pd.DataFrame(ordinal.fit_transform(df[['salary_cat']]),columns=df[['salary_cat']].columns)\n",
    "#y = np.hstack(y)\n",
    "X = df1.drop('salary_cat',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test),columns=X_test.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline((\n",
    "    ('clf',KNeighborsClassifier()),\n",
    "))\n",
    "\n",
    "parameter1 = {'clf__metric': ['minkowski','euclidean'],\n",
    "              'clf__n_jobs': [-1],\n",
    "              'clf__n_neighbors': range(1,50),\n",
    "              'clf__weights': ['uniform','distance']}\n",
    "\n",
    "grid1 = (pipeline1,parameter1)\n",
    "\n",
    "##########################################\n",
    "pipeline2 = Pipeline((\n",
    "    ('pre',SalaryPreprocessor(columns_to_drop=columns_to_drop,\n",
    "                            columns_to_dummify=columns_to_dummify,\n",
    "                            columns_to_str=columns_to_str,\n",
    "                           columns_for_tfidf=columns_for_tfidf)),\n",
    "    ('scale',StandardScaler(with_mean=False)),\n",
    "    ('clf',LogisticRegression()),\n",
    "))\n",
    "\n",
    "parameter2 = {'clf__verbose':[2],\n",
    "              'clf__random_state':[0],\n",
    "              'clf__max_iter':[10000],\n",
    "              'clf__C': np.logspace(-2,0,10),\n",
    "              'clf__fit_intercept': [True,False],\n",
    "              'clf__penalty': ['l2','l1'],\n",
    "              'clf__solver': ['liblinear']}\n",
    "\n",
    "\n",
    "grid2 = (pipeline2,parameter2)\n",
    "##########################################\n",
    "pipeline3 = Pipeline((\n",
    "    ('clf',MultinomialNB()),\n",
    "))\n",
    "\n",
    "parameter3 = {'clf__alpha': np.logspace(-4,-2,10)}\n",
    "\n",
    "\n",
    "\n",
    "grid3 = (pipeline3,parameter3)\n",
    "##########################################\n",
    "pipeline4 = Pipeline((\n",
    "    ('clf',SVC()),\n",
    "))\n",
    "\n",
    "parameter4 = {'clf__C': np.logspace(-2,0,20),\n",
    "             'clf__gamma': np.logspace(-2,0,20),\n",
    "             'clf__kernel': ['rbf', 'poly'],\n",
    "             'clf__max_iter': [-1],\n",
    "             'clf__random_state': [0],\n",
    "             'clf__verbose': [2]}  \n",
    "\n",
    "grid4 = (pipeline4,parameter4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = [grid1,grid2,grid3,grid4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r\"\\.([A-Z]+.[A-Za-z]+)\",str(pipeline4.get_params()['clf'].__class__)).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compare(grids):\n",
    "    \n",
    "    results_dict = {}\n",
    "    for i in range(len(grids)):\n",
    "\n",
    "        grid_s = GridSearchCV(grids[i][0],grids[i][1],verbose=2,n_jobs=-1,cv=5)\n",
    "        grid_s.fit(X_train,y_train)\n",
    "        estimator_name = re.search(r\"\\.([A-Z]+.[A-Za-z]+)\",str(grid_s.get_params()['estimator__clf'].__class__)).group(1)\n",
    "        results_dict[estimator_name] = [grid_s.best_score_]\n",
    "        results_dict[estimator_name].append(grid_s.best_params_)\n",
    "    \n",
    "    return (grid_s,results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids=[grid2]\n",
    "model_grid = model_compare(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grids=[grid2]\n",
    "model_grid = model_compare(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',5000)\n",
    "grid_df = pd.DataFrame(model_grid[1],index=['score','best_params']).T\n",
    "\n",
    "grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model_grid[0].predict(X_test)\n",
    "confusion_matrix(y_test,y_pred_test,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_grid[0].predict(X)\n",
    "confusion_matrix(y,y_pred,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids=[grid2]\n",
    "\n",
    "best_model = model_compare(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = best_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred_test,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_test,labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model[0].fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = best_model[0].best_params_['clf__C']\n",
    "best_penalty = best_model[0].best_params_['clf__penalty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model[0].estimator.steps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model[0].estimator.steps[0][1].set_params(C=best_C,penalty=best_penalty,random_state=0,solver='liblinear').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(np.hstack(best_model[0].estimator.steps[0][1].coef_),index=X_train.columns,columns=['coef'])\n",
    "\n",
    "coefficients['coef_abs'] = coefficients.coef.apply(abs)\n",
    "\n",
    "coefficients.sort_values(by='coef_abs',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(grid_df.loc['LogisticRegression','best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2.set_params(clf__C =0.0774263682681127,\n",
    "                     clf__penalty = 'l1', \n",
    "                     clf__solver = 'liblinear', clf__verbose=1,\n",
    "                    clf__max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(pipeline2,X_train,y_train,cv=5).mean()\n",
    "cross_val_score(pipeline2,X_train,y_train,cv=5).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(grid_s,X_train,y_train,cv=5).mean()\n",
    "cross_val_score(grid_s,X_train,y_train,cv=5).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression(n_jobs=-1,verbose=1,random_state=0,max_iter=10000)\n",
    "\n",
    "param_grid = {'metric': ['minkowski','euclidean'],\n",
    "              'n_jobs': [-1],\n",
    "              'verbose':[1],\n",
    "              'random_state':[0],\n",
    "              'max_iter':[10000],\n",
    "              'n_neighbors': range(1,50),\n",
    "              'weights': ['uniform','distance'],\n",
    "             'C': np.logspace(-1,0,10),\n",
    "             'fit_intercept': [True,False],\n",
    "             'penalty': ['l2','l1'],\n",
    "             'solver': ['liblinear']}\n",
    "\n",
    "grid_estimator = GridSearchCV([knn,logr], param_grid=param_grid,n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_estimator.score(X_train,y_train)\n",
    "grid_estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(grid_estimator,X_train,y_train,cv=5,n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "neighbors = range(1,50)\n",
    "for neigh in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=neigh,n_jobs=-1)\n",
    "    knn.fit(X_train,y_train)\n",
    "    scores.append(cross_val_score(knn,X_train,y_train,cv=5,n_jobs=-1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = np.array(scores)\n",
    "plt.plot(x,scores);\n",
    "\n",
    "\n",
    "#Maximum k occurs at 24 neighbors\n",
    "scores.argmax()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=scores.argmax()+1,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training score:{knn.score(X_train,y_train):.3f}\")\n",
    "print(f\"Testing score:{knn.score(X_test,y_test):.3f}\")\n",
    "print(f\"Cross Validation score:{cross_val_score(knn,X_train,y_train,cv=5,n_jobs=-1).mean():.3f}\")\n",
    "print(f\"Cross Validation variance:{cross_val_score(knn,X_train,y_train,cv=5,n_jobs=-1).std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred_test,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_test,labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
